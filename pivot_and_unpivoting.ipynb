{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013fdbdb-751d-4d6b-9eb0-f1f8fd74663c",
   "metadata": {},
   "source": [
    "## ***Pivoting and Unpivoting***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d8aaf-b5ff-4c70-a09f-c11cc689172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9590b674-733b-474d-830d-7574628ee8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data    \n",
    "pq = pd.read_csv(\"PQ Exercise 1d.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the columns in the dataframe\n",
    "pq.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9f227",
   "metadata": {},
   "source": [
    "- You'll notice in the results of the cell above and below is that a lot of features of this dataframe are dates and only three seem to be actual feature names that we see regularly in datasets. Let's investigate further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7158e4-baca-4fa4-ba25-4a63dc75412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f681d",
   "metadata": {},
   "source": [
    "- You'll notice that in the \"Metric\" column, it has two items, \"Sales\" and \"Margin\". Let's proceed to do something called unpivoting or melting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9938917",
   "metadata": {},
   "source": [
    "### **Unpivoting (Melt) the Data**\n",
    "- Transforming the wide format (where dates are columns) into a long format (where dates become rows), using the melt function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c98861-0171-433e-a7c5-a10fa0f6ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.melt(pq, id_vars = [\"Metric\", \"Store\", \"Cat\"], var_name = \"Date\", value_name = \"Value\")\n",
    "# id_vars: These are the columns that will remain as identifiers (in the case, Store, Cat, and Metric)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61332acc",
   "metadata": {},
   "source": [
    "- We invoke the melt method that works directly with pandas.\n",
    "- The \"id_vars\" are identifier variables, these are the features that we like and what them to remain there, unmelted.\n",
    "- The \"var_name\" are the measured variables, these are the columns that you want to create where the melted data falls under and,\n",
    "- The value_name\" is telling python to all the values under the \"Date\" column will be melted under the newly created column (which is in \"value\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1557f0d-432d-4511-9e07-262b6824bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577df4d",
   "metadata": {},
   "source": [
    "- You can recognise the stack difference between the first dataframe and this new dataframe. But data preprocessing work isn't done yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161be872-f9c7-4099-8a65-ece0d495a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb574454-b5c0-4cbe-8a88-d847b413a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85753518-5a25-46c0-aa34-37fb21eaf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487edada",
   "metadata": {},
   "source": [
    "- If you observe the dataframe, you'll notice that the NaN that comes after either \"Sales\" or \"Margin\" should have been registered as \"Sales\" and \"Margin\". \n",
    "- It's like when you're physically registering items in the drawn table in a notebook and you decide to use \"//\" or \"\" just to show that there's a repetition of the same item as written above it. \n",
    "- What we're going to do now is to make sure that all cells that should \"Sales\" in them so be registered so and likewise for \"Margin\".\n",
    "- That will introduce us to the ffill() method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c9b298",
   "metadata": {},
   "source": [
    "### ***Fill Down Missing Values in the Metric Column***\n",
    "- To fill down the Metric Column, use ffill() (forward fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0046d5-59d7-4fb8-ac1d-58870d30a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill down the Metric Column\n",
    "df[\"Metric\"] = df[\"Metric\"].ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b407438",
   "metadata": {},
   "source": [
    "- The ffill() method tells python to check the item in the dataframe ans fill down or fill forward accordingly until you meet another item and do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df66274-de13-4b0b-ace2-8c6f858a6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf141a",
   "metadata": {},
   "source": [
    "- Our preprocessing continues, you'll also notice that the Metric columns isn't necessary, because we have a lot of \"Sales\" instances and \"Margin\" instances and those could be there own columns, housing their own data. Chaning that is called pivoting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7370be",
   "metadata": {},
   "source": [
    "### ***Pivot the Data (Spread Metric into Sales and Margin)***\n",
    "- Now that the Metric column is filled, you can pivot the data to separate Sales and Margin into different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a5184-fc3e-4588-aee7-3ab0f7a3c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.pivot_table(index = [\"Store\", \"Cat\", \"Date\"], columns = \"Metric\", values = \"Value\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a729c0",
   "metadata": {},
   "source": [
    "- To do this we invoked the pivot_table() method.\n",
    "- The \"index\" parameter includes a list of items that are the column names of the columns that needs to remain untourched in the dataframe.\n",
    "- the \"columns\" parameter takes in the name of the column (in this case \"Metric\") that we wanted pivoted.\n",
    "- The \"values\" parameter just talls python to use the corresponding value.\n",
    "- \"reset_index\" gives us a new set of indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74932d-46cc-4b11-a627-c727df10329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a671bd",
   "metadata": {},
   "source": [
    "- Notice the changes?\n",
    "- What can you observe?\n",
    "\n",
    "- The next agenda is to remove the column name metric from the dataframe because it holds the indexes and the indexes doesn't need a column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae4bd14-fd0a-4122-97f1-011794e1d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd2d5c-d376-4fc7-9c99-6137437bd12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ec46f-8327-465b-89f8-aa33ec2e5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86fabab-a340-4e3f-a74f-6f0d4a1ab236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b9a058",
   "metadata": {},
   "source": [
    "- The next step in our preprocessing process is to convert the items in our date column from \"object\" to \"datetime\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b45c8",
   "metadata": {},
   "source": [
    "### ***Convert the Data Column to a Datetime Object***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0eff2-84a6-4e12-afeb-0be160258130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors = \"coerce\", format = \"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f05223",
   "metadata": {},
   "source": [
    "- If you're not aware of all the conditions that occurs under the date columns, like the multiple null values, just use the parameter \"errors\" and set it to \"coerce\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511b66b-004e-4648-ad6a-c20ffad69bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c8653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing null values\n",
    "df[\"Date\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6507bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().drop(columns= \"index\", axis = 1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355a49f0",
   "metadata": {},
   "source": [
    "- Creating new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694edb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Profit\"] = round((df[\"Margin\"] * df[\"Sales\"]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5144c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"COGS\"] = round((df[\"Sales\"] - df[\"Profit\"]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a9acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Month\"] = df[\"Date\"].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c25196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"] = df[\"Date\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f84178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Expenses\"] = df[\"Sales\"] - df[\"Profit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e5aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfd4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Month\")[\"Profit\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0091fa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {\"Cat\" : \"Category\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Store\")[\"Sales\"].sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Year\").agg({\"Sales\":\"sum\", \"Profit\" : \"sum\", \"Margin\" : \"mean\", \"Expenses\" : \"sum\"}).sort_values(by = \"Profit\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Category\").agg({\"Sales\":\"sum\", \"Profit\" : \"sum\", \"Margin\" : \"mean\", \"Expenses\" : \"sum\"}).sort_values(by = \"Profit\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4956ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Month\", \"Year\"]).agg({\"Sales\":\"sum\", \"Profit\" : \"sum\", \"Margin\" : \"mean\", \"Expenses\" : \"sum\"}).sort_values(by = \"Margin\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1058e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
